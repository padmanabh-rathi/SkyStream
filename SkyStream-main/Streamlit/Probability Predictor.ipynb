{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunne"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYnU9tveXZ6r",
        "outputId": "58aa4669-e66b-4e49-b047-9270a2967b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94mcode\u001b[39m E404\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m Not Found - GET https://registry.npmjs.org/localtunne - Not found\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m  'localtunne@*' is not in this registry.\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m Note that you can also install from a\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m \u001b[94m404\u001b[39m tarball, folder, http url, or git url.\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K\u001b[1mnpm\u001b[22m \u001b[31merror\u001b[39m A complete log of this run can be found in: /root/.npm/_logs/2025-05-09T18_49_25_573Z-debug-0.log\n",
            "\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2o8FnuSuioUchcVkQGWsDKHwcRW_28rmkZ86ALGpoVdkgwHx1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgEfshBHYKGa",
        "outputId": "12dea198-dbb3-48a4-f0af-a65ba07e0738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok lightgbm"
      ],
      "metadata": {
        "id": "TZs3DVSpa63H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import joblib\n",
        "\n",
        "# Load your dataset (make sure it's uploaded to Colab)\n",
        "df = pd.read_csv(\"balanced_features.csv\")  # You can upload this using Colab's sidebar\n",
        "#20k total data (10k-delay/10k-not delay)\n",
        "\n",
        "# Define features and label\n",
        "features = ['is_weekend', 'is_peak_hour', 'is_summer_month', 'is_airline_lowcost',\n",
        "            'departure_month', 'departure_dayofweek', 'taxi_time_ratio']\n",
        "X = df[features]\n",
        "y = df['DepDel15']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train LightGBM\n",
        "lgb_model = LGBMClassifier()\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = lgb_model.predict(X_test)\n",
        "y_prob = lgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"🧠 LightGBM Results:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"✅ ROC AUC:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Save model\n",
        "joblib.dump(lgb_model, \"lightgbm_model.pkl\")\n",
        "print(\"✅ Model saved as lightgbm_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVeSIzmJa605",
        "outputId": "7cfe8f42-38e0-45f2-90ca-2d01f4323d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 7947, number of negative: 8002\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 267\n",
            "[LightGBM] [Info] Number of data points in the train set: 15949, number of used features: 4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498276 -> initscore=-0.006897\n",
            "[LightGBM] [Info] Start training from score -0.006897\n",
            "🧠 LightGBM Results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.77      0.71      1978\n",
            "         1.0       0.72      0.60      0.66      2010\n",
            "\n",
            "    accuracy                           0.68      3988\n",
            "   macro avg       0.69      0.68      0.68      3988\n",
            "weighted avg       0.69      0.68      0.68      3988\n",
            "\n",
            "✅ ROC AUC: 0.735040419741535\n",
            "✅ Model saved as lightgbm_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "st.set_page_config(page_title=\"✈️ Flight Delay Predictor\")\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return joblib.load(\"lightgbm_model.pkl\")\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "\n",
        "st.title(\"✈️ Flight Delay Predictor\")\n",
        "\n",
        "st.markdown(\"Fill in the flight details below to predict whether the flight will be delayed.\")\n",
        "\n",
        "st.sidebar.header(\"Flight Features\")\n",
        "\n",
        "is_weekend = st.sidebar.selectbox(\"Is Weekend?\", [0, 1])\n",
        "is_peak_hour = st.sidebar.selectbox(\"Is Peak Hour?\", [0, 1])\n",
        "is_summer_month = st.sidebar.selectbox(\"Is Summer Month?\", [0, 1])\n",
        "is_airline_lowcost = st.sidebar.selectbox(\"Is Low-Cost Airline?\", [0, 1])\n",
        "departure_month = st.sidebar.slider(\"Departure Month\", 1, 12, 6)\n",
        "departure_dayofweek = st.sidebar.slider(\"Day of Week (0=Mon, 6=Sun)\", 0, 6, 0)\n",
        "taxi_time_ratio = st.sidebar.slider(\"Taxi Time Ratio\", 0.0, 3.0, 1.0)\n",
        "\n",
        "input_data = pd.DataFrame({\n",
        "    'is_weekend': [is_weekend],\n",
        "    'is_peak_hour': [is_peak_hour],\n",
        "    'is_summer_month': [is_summer_month],\n",
        "    'is_airline_lowcost': [is_airline_lowcost],\n",
        "    'departure_month': [departure_month],\n",
        "    'departure_dayofweek': [departure_dayofweek],\n",
        "    'taxi_time_ratio': [taxi_time_ratio]\n",
        "})\n",
        "\n",
        "if st.button(\"Predict Delay\"):\n",
        "    prediction = model.predict(input_data)[0]\n",
        "    prob = model.predict_proba(input_data)[0][1]\n",
        "\n",
        "    st.subheader(\"📈 Prediction Result:\")\n",
        "    if prediction == 1:\n",
        "        st.error(f\"The model predicts a **delay** with a probability of {prob:.2f}.\")\n",
        "    else:\n",
        "        st.success(f\"The model predicts **on-time** departure with a probability of {1 - prob:.2f}.\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"streamlit.py\", \"w\") as f:\n",
        "    f.write(streamlit_code)"
      ],
      "metadata": {
        "id": "UM7F56gqa6yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading, time, os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "ngrok.kill()  # stop previous tunnels\n",
        "\n",
        "def run():\n",
        "    os.system(\"streamlit run streamlit.py\")\n",
        "\n",
        "thread = threading.Thread(target=run)\n",
        "thread.start()\n",
        "time.sleep(5)\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"🚀 Your Streamlit app is live at: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We_6LrAua6v4",
        "outputId": "e435782a-a904-413f-e75b-db1a1a9fe1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Your Streamlit app is live at: NgrokTunnel: \"https://55c1-35-199-9-138.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t3yAdgCJa6tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tW34ImRBa6q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYfAF4Jia6ob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}